# Audio/video transcription configuration
# Copy this file to config.yaml and customize it

# Whisper model to use
# Options: tiny, base, small, medium, large-v2, large-v3
# Larger models provide better quality but are slower
model: large-v3

# Compute device
# Options: auto, cuda, cpu
# "auto" automatically detects if a CUDA GPU is available
device: auto

# Transcription language
# ISO 639-1 code (fr, en, de, es, etc.)
language: fr

# Speaker identification (diarization)
# Requires a valid HuggingFace token
diarize: true

# Advanced parameters
batch_size: 16    # Batch size (reduce if memory error)
beam_size: 5      # Beam size for decoding (higher = better but slower)
